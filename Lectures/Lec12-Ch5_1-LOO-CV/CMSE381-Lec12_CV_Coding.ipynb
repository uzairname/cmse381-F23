{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dfd68f5",
   "metadata": {},
   "source": [
    "# Lab: Validation set and Cross-Validation\n",
    "## CMSE 381 - Fall 2022\n",
    "## Oct 2,  2023. Lecture 12\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea3a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everyone's favorite standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d0c63f",
   "metadata": {},
   "source": [
    "# 1. Validation set\n",
    "\n",
    "\n",
    "\n",
    "The first thing we will do is try out the validation set approach. We've already used this some in class so this should be review.\n",
    "\n",
    "\n",
    "## Validation set on toy data\n",
    "\n",
    "First off, let's generate some toy data just to mess around. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e321f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed so everyone has the same numbers\n",
    "np.random.seed(42)\n",
    "\n",
    "def f(t, m = -3, b = 2):\n",
    "    return m*t+b\n",
    "\n",
    "n = 300\n",
    "X_toy = np.random.uniform(0,5,n)\n",
    "y_toy = f(X_toy) + np.random.normal(0,2,n)\n",
    "\n",
    "# reshaping to deal with cranky code later\n",
    "X_toy = X_toy.reshape(-1,1)\n",
    "y_toy = y_toy.reshape(-1,1)\n",
    "\n",
    "plt.scatter(X_toy,y_toy)\n",
    "plt.plot(X_toy,f(X_toy),c = 'red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf3fe63",
   "metadata": {},
   "source": [
    "Ok, so now we have our fake data set up.  Extracting training and testing sets is as simple as the following single line.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f157ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "randomseed = 48824\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_toy,y_toy, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=randomseed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d094a6aa",
   "metadata": {},
   "source": [
    "What this does is extracts two pairs of input/output variables $X$ and $y$.  The train we will use to train our models, and then we will test (or validate) them on the test data. \n",
    "\n",
    "One way to see what these sets are is to plot them, although usually we have much higher $p$ (a.k.a. way more input variables) so we can't really visualize like this normally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f269e617",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_train,y_train, marker = '+', label = \"Training\")\n",
    "plt.scatter(X_test,y_test, marker = '*', label = \"Testing\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df821b9",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Do this:</font>** Set up a linear regression model, train it on the training set, and test it on the test set.  What is your mean squared error? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c89069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9500f236",
   "metadata": {},
   "source": [
    "Now that we can see what happens in one case, let's try doing this many times.  \n",
    "The code below changes our random seed. \n",
    "\n",
    "&#9989; **<font color=red>Do this:</font>** Copy the code needed to generate a train/test split with the new seed and compute the MSE. \n",
    "\n",
    "&#9989; **<font color=red>Q:</font>** What happens to the MSE? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7870bf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running this changes the random seed to get a new split of the data\n",
    "randomseed +=1\n",
    "\n",
    "\n",
    "# Put your code here to generate a new train test split, run a new model, and compute the MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09ba2a6",
   "metadata": {},
   "source": [
    "\n",
    "&#9989; **<font color=red>Do this:</font>**  Run the above script in a loop, repeating $k=30$ times. Keep track of the MSE in a list and draw a histogram of the results. What do you notice? If you want to see more pattern, set $k$ to be something larger like 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d17f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430024cc",
   "metadata": {},
   "source": [
    "\n",
    "![Stop Icon](https://upload.wikimedia.org/wikipedia/commons/thumb/1/1e/Vienna_Convention_road_sign_B2a.svg/180px-Vienna_Convention_road_sign_B2a.svg.png)\n",
    "\n",
    "Great, you got to here! Hang out for a bit, there's more lecture before we go on to the next portion. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006fbd25",
   "metadata": {},
   "source": [
    "# 2. Leave One Out Cross Validation (LOOCV)\n",
    "\n",
    "Luckily, `sklearn` has a simple built in procedure to extract your LOOCV splits for easily passing to your models. However, these work a bit differently than before. As always, the `sklearn` documentation and user guide is an excellent place to start. \n",
    "\n",
    "- [LOOCV Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneOut.html)\n",
    "- [LOOCV User guide](https://scikit-learn.org/stable/modules/cross_validation.html#leave-one-out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa8b2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm copying the same code from above just so we're restarting with the same data. \n",
    "\n",
    "\n",
    "# Set the seed so everyone has the same numbers\n",
    "np.random.seed(42)\n",
    "\n",
    "def f(t, m = -3, b = 2):\n",
    "    return m*t+b\n",
    "\n",
    "n = 300\n",
    "X_toy = np.random.uniform(0,5,n)\n",
    "y_toy = f(X_toy) + np.random.normal(0,2,n)\n",
    "\n",
    "# reshaping to deal with cranky code later\n",
    "X_toy = X_toy.reshape(-1,1)\n",
    "y_toy = y_toy.reshape(-1,1)\n",
    "\n",
    "plt.scatter(X_toy,y_toy)\n",
    "plt.plot(X_toy,f(X_toy),c = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff0e6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(X_toy)\n",
    "\n",
    "# Notice that trying to print loo doesn't give us much that's useful\n",
    "print(loo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e58c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The power of the function shows up when we use it in a for loop:\n",
    "for train_index, test_index in loo.split(X_toy):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ffcf23",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Question:</font>** What's the difference between the `LOO.split` output and the `train_test_split` from before?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cd4cc3",
   "metadata": {},
   "source": [
    "Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b62deb",
   "metadata": {},
   "source": [
    "The code below fixes the problem, and draws a figure like above where we get to see which data point is part of the testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddca37ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These generator objects are a bit weird, so I can't just pull one split\n",
    "# out of the list. The code below is a bit convoluted, but essentially I'm \n",
    "# just trying to draw the last train/test split found. \n",
    "countPrint = 0\n",
    "maxPrint = 7 # If you change this number, a different point will be labeled as \n",
    "             # the testing point because I make the loop stop at maxPrint.\n",
    "\n",
    "for train_index, test_index in loo.split(X_toy):\n",
    "\n",
    "    countPrint +=1 \n",
    "\n",
    "    X_train, X_test = X_toy[train_index], X_toy[test_index]\n",
    "    y_train, y_test = y_toy[train_index], y_toy[test_index]\n",
    "    \n",
    "    # Uncomment if you want to see how this fixes it\n",
    "#     print(X_train,y_train)\n",
    "#     print(X_test, y_test)\n",
    "#     print('\\n')\n",
    "\n",
    "    if countPrint >= maxPrint:\n",
    "        break\n",
    "\n",
    "plt.scatter(X_train,y_train, marker = '+', label = \"Training\")\n",
    "plt.scatter(X_test,y_test, marker = '*', label = \"Testing\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446eb709",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Do this:</font>** Use the leave one out splits to perform a linear regression on each one, return the mean squared error, and then average over all the values to get the LOOCV error estimation.\n",
    "\n",
    "What do you notice about this error estimation vs. the validation set version above? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b5524d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20b6123",
   "metadata": {},
   "source": [
    "## The easier version\n",
    "\n",
    "Ok I lied to you a bit. There's an even easier version of this whole LOO-CV thing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908730cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This command does all your work for you\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "#define cross-validation method to use\n",
    "cv = LeaveOneOut()\n",
    "\n",
    "#build linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "#use LOOCV to evaluate model\n",
    "scores = cross_val_score(model, X_toy, y_toy, \n",
    "                         scoring='neg_mean_squared_error',\n",
    "                         cv=cv)\n",
    "\n",
    "#view mean absolute error\n",
    "np.average(np.absolute(scores))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1e99a5",
   "metadata": {},
   "source": [
    "Check out this number. Remember LOO-CV has no randomness in it so you should have the same number here as you calculated previously. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f79113",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "-----\n",
    "### Congratulations, we're done!\n",
    "Written by Dr. Liz Munch, Michigan State University\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\">Creative Commons Attribution-NonCommercial 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb8354f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "3e3338d56a43a0108f5ff8ffc1915439f9812d920a0d5bf5d66e4a60c981234a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
